{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines on the D-Wave Quantum Annealer\n",
    "#### Created by Gabriele Cavallaro (g.cavallaro@fz-juelich.de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setting Up the Access to the D-Wave 2000Q quantum computer\n",
    "\n",
    "- Make a free account to run on the D-Wave through [Leap](https://www.dwavesys.com/take-leap)\n",
    "\n",
    "- Install Ocean Software with [pip install dwave-ocean-sdk](https://docs.ocean.dwavesys.com/en/latest/overview/install.html)\n",
    "\n",
    "- Configuring the D-Wave System as a Solver with [dwave config create](https://docs.ocean.dwavesys.com/en/latest/overview/dwavesys.html#dwavesys)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load of the Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * # It contains functions for threat the data (I/O, encoding/decoding) and metrics for evaluations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Select the Dataset\n",
    "\n",
    "##### In this notebook we consider the datasets of [HyperLabelMe](http://hyperlabelme.uv.es/index.html) (i.e., a benchmark system for remote sensing image classification). \n",
    "\n",
    "- It contains 43 image datasets, both multi- and hyperspectral\n",
    "- For each one, training pairs (spectra and their labels) and test spectra are provided\n",
    "- The test labels are not given. The predicted labels needs to be uploaded in HyperLabelMe which will return the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Ima40.txt can be downloaded after registering at [1]\n",
    "id_dataset='Im40'\n",
    "[X_train, Y_train, X_test]=dataread('input_datasets/hyperlabelme/'+id_dataset+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Background on Support Vector Machines (SVMs)\n",
    "\n",
    "A SVM learns its parameters from a set of annotated training samples\n",
    "\n",
    "- $D=\\left\\{\\textbf{x}_{n}, y_{n}: n=0, \\ldots, N-1\\right\\}$\n",
    "- with $\\textbf{x}_{n} \\in \\mathbb{R}^{d}$ being a feature vector and $y_n$ its label. \n",
    "\n",
    "A SVM separates the samples of different classes in their feature space by tracing maximum margin hyperplanes.\n",
    "\n",
    "The training consists of solving a [quadratic programming (QP)](https://www.cambridge.org/us/academic/subjects/mathematics/numerical-recipes/numerical-recipes-art-scientific-computing-3rd-edition?format=HB&utm_source=shortlink&utm_medium=shortlink&utm_campaign=numericalrecipes) problem.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:qp_equation}\n",
    "L=\\frac{1}{2} \\sum_{n m} \\alpha_{n} \\alpha_{m} y_{n} y_{m} k\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right)-\\sum_{n} \\alpha_{n} \\qquad \\qquad \\qquad \\text { (1) }\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:svm_constrains}\n",
    "\\text {subject to} \\quad 0 \\leq \\alpha_{n} \\leq C  \\> \\> \\text { and } \\> \\> \\sum_{n} \\alpha_{n} y_{n}=0 \\qquad  \\qquad  \\text { (2) }\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "For $N$ coefficients $\\alpha_{n} \\in \\mathbb{R}$, where $C$ is a regularization parameter and $k(.,.)$ is a kernel function that enables a SVM to compute non-linear decision functions (by means of the kernel trick \n",
    "[kernel trick](https://dl.acm.org/citation.cfm?id=559923)). \n",
    "The type of kernel function which is most commonly used is the RBF:\n",
    "$\\operatorname{rbf}\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right)=e^{-\\overline{\\gamma}\\left\\|\\mathbf{x}_{n}-\\mathbf{x}_{m}\\right\\|^{2}}$.\n",
    "\n",
    "The SVM decision boundary is based on the samples corresponding to $\\alpha_{n} \\neq 0$ (i.e., support vectors).\n",
    "A typical solution often contains many $\\alpha_{n}=0$. \n",
    "The prediction for an arbitrary\n",
    "sample $\\mathbf{x} \\in \\mathbb{R}^{d}$ can be made by evaluating the decision function (i.e., signed distance between the sample $\\mathbf{x}$ and the decision boundary)\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:decision_function}\n",
    "f(\\mathbf{x})=\\sum_{n} \\alpha_{n} y_{n} k\\left(\\mathbf{x}_{n}, \\mathbf{x}\\right)+b \\qquad  \\qquad  \\text { (3) }\n",
    "\\end{equation}\n",
    "\n",
    "where the bias $b$ can be computed by\n",
    "\n",
    "\\begin{equation}\n",
    "b=\\frac{\\sum_{n} \\alpha_{n}\\left(C-\\alpha_{n}\\right)\\left[y_{n}-\\sum_{m} \\alpha_{m} y_{m} k\\left(\\mathbf{x}_{m}, \\mathbf{x}_{n}\\right)\\right]}{\\sum_{n} \\alpha_{n}\\left(C-\\alpha_{n}\\right)} \\qquad  \\qquad  \\text { (4) }\n",
    "\\end{equation}\n",
    "\n",
    "The class label for $\\mathbf{x}$ predicted  is $\\widetilde{y}=\\operatorname{sign}(f(\\mathbf{x}))$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Quantum SVM\n",
    "\n",
    "The DW2000Q QA requires the SVM training to be formulated as a [Quadratic Unconstrained Binary Optimization (QUBO)](https://docs.dwavesys.com/docs/latest/c_gs_3.html) problem which is defined as the minimization of the energy function:\n",
    "\n",
    "\\begin{equation}\n",
    "E=\\sum_{i \\leq j} a_{i} Q_{i j} a_{j} \\qquad  \\qquad  \\text { (5) }\n",
    "\\end{equation}\n",
    "\n",
    "with $a_{i} \\in\\{0,1\\}$ the binary variables of the optimization problem, and $Q$ \n",
    "the QUBO weight matrix (i.e., an upper-triangular matrix of real numbers).\n",
    "\n",
    "Since the solution of Eqs. (1)-(2) consists of real numbers $\\alpha_{n} \\in \\mathbb{R}$ and Eq.(4) can only computes discrete solutions, the following encoding is used: \n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:encoding}\n",
    "\\alpha_{n}=\\sum_{k=0}^{K-1} B^{k} a_{K n+k} \\qquad  \\qquad  \\text { (6) }\n",
    "\\end{equation}\n",
    "\n",
    "where $a_{K n+k} \\in\\{0,1\\}$ are binary variables, $K$ is the number of\n",
    "binary variables to encode $\\alpha_{n}$, and $B$ is the base used for the\n",
    "encoding. \n",
    "\n",
    "\n",
    "The formulation of the QP of Eqs. (1)-(2) as QUBO is obtained through the encoding of Eq. (6) and the introduction of a multiplier $\\xi$ to include the first constraint of Eq. (2) as a squared penalty term:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:formulation_qp_quantum_1}\n",
    "E=\\frac{1}{2} \\sum_{n m k j} a_{K n+k} a_{K m+j} B^{k+j} y_{n} y_{m} k\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right)\n",
    "-\\sum_{n k} B^{k} a_{K n+k}+\\xi\\left(\\sum_{n k} B^{k} a_{K n+k} y_{n}\\right)^{2}  \\qquad  \\qquad  \\text { (7) }\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:formulation_qp_quantum_2}\n",
    " =\\sum_{n, m=0}^{N-1} \\sum_{k, j=0}^{K-1} a_{K n+k} \\widetilde{Q}_{K n+k, K m+j} a_{K m+j}   \\qquad  \\qquad  \\text { (8) }\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where $\\widetilde{Q}$ is a matrix of size $K N \\times K N$ given by \n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:q_embedding}\n",
    "\\widetilde{Q}_{K n+k, K m+j} =\\frac{1}{2} B^{k+j} y_{n} y_{m}\\left(k\\left(\\mathbf{x}_{n}, \\mathbf{x}_{m}\\right)+\\xi\\right)  -\\delta_{n m} \\delta_{k j} B^{k}   \\qquad  \\qquad  \\text { (9) }\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "Since $\\widetilde{Q}$ is symmetric, the upper-triangular \\ac{QUBO} matrix $Q$ is defined by \n",
    "$Q_{i j}=\\widetilde{Q}_{i j}+\\widetilde{Q}_{j i}$ for $i<j$ and $Q_{i i}=\\widetilde{Q}_{i i}$. The second constraint of Eq. (2) is automatically included in Eq. (8) through the encoding given in Eq. (6), since the maximum for $\\alpha_{n}$ is given by \n",
    "\n",
    "\\begin{equation}\n",
    "C=\\sum_{k=1}^{K} B^{k}  \\qquad  \\qquad  \\text { (10) }\n",
    "\\end{equation}\n",
    "\n",
    "The last step required to run the optimization on the DW2000Q QA is the embedding procedure.\n",
    "This is necessary because the QUBO problem given in Eq. (5) includes some couplers $Q_{i,j}\\neq0$ between qubit $i$ and qubit $j$ for which no physical connection exists on the chip (i.e., constraint of the Chimera topology of the DW2000Q quantum processor).\n",
    "The embedding increases the number of logical connections between the qubits.\n",
    "When no embedding can be found, the number of nonzero couplers $n_{cpl}$ is the parameter that can be reduced until an embedding is found. \n",
    "\n",
    "The DW2000Q QA computes a variety of close-to-optimal solutions (i.e., different coefficients  $\\{\\alpha_{n}\\}^{(i)}$ obtained from Eq. (6)). Many of these solutions may have a slightly higher\n",
    "energy than the global minimum $\\{\\alpha_{n}\\}^*$ that can be found by the classical SVM. However, these solutions can still solve the classification problem for the training data.\n",
    "For each run on the DW2000Q QA, the 20 lowest energy samples from 10,000 reads are kept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Quantum SVM: Calibration Phase\n",
    "\n",
    "The SVM on the QA depends on four hyperparameters:\n",
    "the encoding base $B$, the number $K$ of qubits per coefficient $\\alpha_{n}$, the multiplier $\\xi$, and the kernel parameter $\\gamma$. The parameter $n_{cpl}$ varies for each run  and is not a parameter of the SVM itself. \n",
    "\n",
    "The hyperparameters are selected through a 10-fold cross-validation. Each training set includes only 30 samples (i.e., choice due to the limitations of the QA). The validation includes the remaining samples that are used for the evaluation of the performance.  \n",
    "\n",
    "For each dataset, the values are calibrated by evaluating the SVM for $B \\in \\{2, 3, 5, 10\\}$, $K\\in \\{2, 3\\}$, $\\xi \\in \\{0, 1, 5\\}$, and $\\gamma\\in \\{ âˆ’1, 0.125, 0.25, 0.5, 1, 2, 4, 8 \\}$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 10-fold Monte Carlo (or split-and-shuffle) cross-validation\n",
    "fold=10\n",
    "\n",
    "for i in range(0,fold):\n",
    "    X_train_cal, X_val_cal, Y_train_cal, Y_val_cal = train_test_split(X_train,Y_train, test_size=0.94, random_state=i)\n",
    "    \n",
    "    # Pre-processing \n",
    "    X_train_cal = preprocessing.scale(X_train_cal)\n",
    "    X_val_cal = preprocessing.scale(X_val_cal)\n",
    "        \n",
    "    # Write the data\n",
    "    write_samples(X_train_cal, Y_train_cal,'input_datasets/calibration/'+id_dataset+'/'+id_dataset+'calibtrain'+str(i))\n",
    "    write_samples(X_val_cal, Y_val_cal,'input_datasets/calibration/'+id_dataset+'/'+id_dataset+'calibval'+str(i))\n",
    "    \n",
    "print('Each training set includes '+str(X_train_cal.shape[0])+ ' samples')\n",
    "print('Each validation set includes '+str(X_val_cal.shape[0])+ ' samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_SVM import *\n",
    "\n",
    "# Hyperparameters \n",
    "B=[2,3,5,10]\n",
    "K=[2,3]\n",
    "xi=[0,1,5]\n",
    "gamma=[-1,0.125,0.25,0.5,1,2,4,8]\n",
    "n_experiments=len(B)*len(K)*len(xi)*len(gamma)\n",
    "\n",
    "hyperparameters=np.zeros([n_experiments,4], dtype=float)\n",
    "\n",
    "path_data_key='input_datasets/calibration/'+id_dataset+'/'\n",
    "data_key = id_dataset+'calibtrain'\n",
    "path_out='outputs/calibration/'+id_dataset+'/'\n",
    "\n",
    "trainacc=np.zeros([fold], dtype=float)\n",
    "trainauroc=np.zeros([fold], dtype=float)\n",
    "trainauprc=np.zeros([fold], dtype=float)\n",
    "    \n",
    "testacc=np.zeros([fold], dtype=float)\n",
    "testauroc=np.zeros([fold], dtype=float)\n",
    "testauprc=np.zeros([fold], dtype=float)\n",
    "\n",
    "trainacc_all=np.zeros([n_experiments], dtype=float)\n",
    "trainauroc_all=np.zeros([n_experiments], dtype=float)\n",
    "trainauprc_all=np.zeros([n_experiments], dtype=float)\n",
    "    \n",
    "testacc_all=np.zeros([n_experiments], dtype=float)\n",
    "testauroc_all=np.zeros([n_experiments], dtype=float)\n",
    "testauprc_all=np.zeros([n_experiments], dtype=float)\n",
    "\n",
    "\n",
    "f = open(path_out+'calibration_results.txt',\"w\") \n",
    "f.write(\"B\\t K\\t xi\\t   gamma\\t trainacc\\t trainauroc\\t trainauprc\\t testacc\\t testauroc\\t testauprc\\n\") \n",
    "  \n",
    "count=0 \n",
    "for x in range(0,len(B)):\n",
    "    for y in range(0,len(K)):\n",
    "        for z in range(0,len(xi)):\n",
    "            for i in range(0,len(gamma)):\n",
    "                for j in range(0,fold):\n",
    "                    path=gen_svm_qubos(B[x],K[y],xi[z],gamma[i],path_data_key,data_key+str(j),path_out)\n",
    "                    pathsub=dwave_run(path_data_key,path)\n",
    "                    [trainacc[j],trainauroc[j],trainauprc[j],testacc[j],testauroc[j],testauprc[j]]=eval_run_rocpr_curves(path_data_key,pathsub,'noplotsave')\n",
    "                    \n",
    "                hyperparameters[count,0]=B[x]\n",
    "                hyperparameters[count,1]=K[y]\n",
    "                hyperparameters[count,2]=xi[z]\n",
    "                hyperparameters[count,3]=gamma[i]\n",
    "            \n",
    "                trainacc_all[count]=np.average(trainacc)\n",
    "                trainauroc_all[count]=np.average(trainauroc)\n",
    "                trainauprc_all[count]=np.average(trainauprc)\n",
    "    \n",
    "                testacc_all[count]=np.average(testacc)\n",
    "                testauroc_all[count]=np.average(testauroc)\n",
    "                testauprc_all[count]=np.average(testauprc)\n",
    "                \n",
    "                np.save(path_out+'hyperparameters', hyperparameters)\n",
    "                np.save(path_out+'trainacc_all', trainacc_all)\n",
    "                np.save(path_out+'trainauroc_all', trainauroc_all)\n",
    "                np.save(path_out+'trainauprc_all', trainauprc_all)\n",
    "                np.save(path_out+'testacc_all', testacc_all)\n",
    "                np.save(path_out+'testauroc_all', testauroc_all)\n",
    "                np.save(path_out+'testauprc_all', testauprc_all)\n",
    "                \n",
    "                f.write(f'{B[x]}\\t {K[y]}\\t {xi[z]}\\t {gamma[i]:8.3f}\\t {np.average(trainacc):8.4f}\\t {np.average(trainauroc):8.4f}\\t {np.average(trainauprc):8.4f}\\t {np.average(testacc):8.4f}\\t {np.average(testauroc):8.4f}\\t {np.average(testauprc):8.4f}')\n",
    "                f.write(\"\\n\") \n",
    "                count=count+1\n",
    "                \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Quantum SVM: Training Phase\n",
    "\n",
    "To overcome the problem of the limited connectivity of the Chimera graph of the DW2000Q QA the whole training set is split into small disjoint subsets $D^{(train,l)}$ of $~40$ samples, with $l=0,...,int(N/40)$. \n",
    "The strategy is to build an ensemble of quantum weak SVMs (qeSVMs) where each classifier is trained on $D^{(train,l)}$. \n",
    "This is achieved in two steps. First, for each subset $D^{(train,l)}$ the twenty best solutions from the DW2000Q QA (i.e., qSVM$(B, K, \\xi , \\gamma )\\#i$ for $i =0, ... ,19$) are combined by averaging over the respective decision functions $f^{l,i}(\\mathbf{x})$ (see Eq. (3)). \n",
    "\n",
    "Since the decision function is linear in the coefficients\n",
    "and the bias $b^{(l,i)}$ is computed from $\\alpha_{n}^{(l,i)}$ via Eq. (4), this procedure effectively results in one classifier with an effective set of coefficients \n",
    "$\\alpha_{n}^{(l)}=\\sum_{i} \\alpha_{n}^{(l, i)} / 20$ and bias \n",
    "$b^{l}=\\sum_{i} b^{(l, i)} / 20$.\n",
    "Second, an average is made over the $int(N/40)$ subsets. \n",
    "\n",
    "Note, however, that the data points \n",
    "$\\left(\\mathbf{x}_{n}^{(l)}, y_{n}^{(l)}\\right) \\in D^{(\\text {train }, l)}$ are now different for each $l$. The full decision function is\n",
    "\n",
    "\\begin{equation}\n",
    "F(\\mathbf{x})=\\frac{1}{L} \\sum_{n l} \\alpha_{n}^{(l)} y_{n}^{(l)} k\\left(\\mathbf{x}_{n}^{(l)}, \\mathbf{x}\\right)+b,\n",
    "\\end{equation}\n",
    "\n",
    "where $b=\\sum_{l} b^{(l)} / L$. As before, the decision for the class label of a point $\\mathbf{x}$ is obtained through $\\widetilde{t}=\\operatorname{sign}(F(\\mathbf{x}))$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_SVM import *\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Write the data\n",
    "experiments=1\n",
    "slice=40 # Number of samples to use for the training\n",
    "fold=int(len(X_train)/40)\n",
    "\n",
    "print(fold)\n",
    "\n",
    "for i in range(0,experiments):    \n",
    "    cv = KFold(n_splits=fold, random_state=i, shuffle=True)\n",
    "    count=0\n",
    "    for test_index, train_index in cv.split(X_train):\n",
    "        #print(\"Train Index: \", len(train_index), \"\\n\")\n",
    "        \n",
    "        X_train_slice, y_train_slice = X_train[train_index], Y_train[train_index]\n",
    "        X_train_slice = preprocessing.scale(X_train_slice)\n",
    "        \n",
    "        X_test_slice, y_test_slice = X_train[test_index], Y_train[test_index]\n",
    "        X_test_slice = preprocessing.scale(X_test_slice)\n",
    "        \n",
    "        write_samples(X_train_slice, y_train_slice,f'input_datasets/train/'+id_dataset+'/'+id_dataset+'calibtrain'+str(i)+'_'+str(count))\n",
    "        write_samples(X_test_slice, y_test_slice,f'input_datasets/train/'+id_dataset+'/'+id_dataset+'calibval'+str(i)+'_'+str(count))\n",
    "        \n",
    "        count=count+1\n",
    "\n",
    "print(\"Each training set has\", len(train_index), \"samples\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the calibration results\n",
    "path_out='outputs/calibration/'+id_dataset+'/'\n",
    "hyperparameters=np.load(path_out+'hyperparameters.npy')\n",
    "testauprc_all=np.load(path_out+'testauprc_all.npy')\n",
    "\n",
    "# Select the best hyperparameter set for the max value of testauprc\n",
    "idx_max = np.where(testauprc_all == np.amax(testauprc_all))\n",
    "B=int(hyperparameters[int(idx_max[0]),0])\n",
    "K=int(hyperparameters[int(idx_max[0]),1])\n",
    "xi=int(hyperparameters[int(idx_max[0]),2])\n",
    "gamma=hyperparameters[int(idx_max[0]),3]\n",
    "print('The best hyperparameters are:\\n'+'B = '+str(B)+' K = '+str(K)+' xi = '+str(xi)+' gamma = '+str(gamma))\n",
    "\n",
    "path_data_key='input_datasets/train/'+id_dataset+'/'\n",
    "data_key = id_dataset+'calibtrain'\n",
    "path_out='outputs/train/'+id_dataset+'/'\n",
    "\n",
    "trained_SVMs=[]\n",
    "\n",
    "for j in range(0,experiments):\n",
    "    for i in range(0,fold):\n",
    "        path=gen_svm_qubos(B,K,xi,gamma,path_data_key,data_key+str(j)+'_'+str(i),path_out)\n",
    "        trained_SVMs.append(dwave_run(path_data_key,path))\n",
    "        np.save(path_out+'trained_SVMs',trained_SVMs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_SVM import *\n",
    "import numpy as np\n",
    "from utils import *\n",
    "path_data_key='input_datasets/train/'+id_dataset+'/'\n",
    "data_key = id_dataset+'calibtrain'\n",
    "\n",
    "[trainacc[j],trainauroc[j],trainauprc[j],testacc[j],testauroc[j],testauprc[j]]=eval_run_rocpr_curves(path_data_key,'outputs/train/im16/runim16calibtrain0_0_B=2_K=3_xi=1_gamma=0.25/result_couplers=2000/','saveplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Quantum SVM: Test Phase\n",
    " \n",
    "The performance of the qeSVMs can be evaluated directly on [HyperLabelMe](http://hyperlabelme.uv.es/index.html) by uploading the predictions (i.e., output file of the next cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_SVM import *\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Pre-processing the test spectra\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "path_data_key='input_datasets/train/'+id_dataset+'/'\n",
    "data_key = id_dataset+'calibtrain'\n",
    "path_train_out='outputs/train/'+id_dataset+'/'\n",
    "path_test_out='outputs/test/'+id_dataset+'/'\n",
    "\n",
    "path_files=np.load(path_train_out+'trained_SVMs.npy')\n",
    "\n",
    "experiments=1\n",
    "slices=10\n",
    "scores=[]\n",
    "\n",
    "for j in range(0,experiments):\n",
    "    for i in range(0,slices):\n",
    "        scores.append(predict(path_data_key,path_files[i],X_test))\n",
    " \n",
    " \n",
    "avg_scores=np.zeros((scores[0].shape[0]))\n",
    "Y_predicted=np.zeros((scores[0].shape[0]),int)\n",
    "\n",
    "for i in range(0,scores[0].shape[0]):\n",
    "    tmp=0\n",
    "    for y in range(0,slices):\n",
    "        tmp=tmp+scores[y][i]\n",
    "    avg_scores[i]=tmp/slices   \n",
    " \n",
    "for i in range(0,scores[0].shape[0]):\n",
    "    if(avg_scores[i]<0):\n",
    "        Y_predicted[i]=1\n",
    "    else:\n",
    "        Y_predicted[i]=2\n",
    "        \n",
    "\n",
    "datawrite(path_test_out,'qeSVM', 'Im16', Y_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "juwels_ker",
   "language": "python",
   "name": "env_juwels"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
